{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "458ebb0e-ef84-49ec-90a0-5206fc7f693c",
   "metadata": {},
   "source": [
    "## **DP1 DIASource Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0258a43-1969-4bd9-b9ff-d8097defb602",
   "metadata": {},
   "source": [
    "## 1. Initialize data & visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2056dd5a",
   "metadata": {},
   "source": [
    "To be run on Rubin Science Platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93dd5f4-a896-4cb2-9e83-0eb54270c76e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from lsst.rsp import get_tap_service\n",
    "from lsst.rsp.service import get_siav2_service\n",
    "from lsst.rsp.utils import get_pyvo_auth\n",
    "\n",
    "import lsst.afw.display as afwDisplay\n",
    "from lsst.afw.image import ExposureF\n",
    "from lsst.afw.math import Warper, WarperConfig\n",
    "from lsst.afw.fits import MemFileManager\n",
    "import lsst.geom as geom\n",
    "\n",
    "from pyvo.dal.adhoc import DatalinkResults, SodaQuery\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from matplotlib.patches import Rectangle\n",
    "from astropy import units as u\n",
    "from astropy.table import Table, vstack\n",
    "import corner\n",
    "from glob import glob\n",
    "from astropy.coordinates import SkyCoord\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import random\n",
    "\n",
    "service = get_tap_service(\"tap\")\n",
    "assert service is not None\n",
    "\n",
    "sia_service = get_siav2_service(\"dp1\")\n",
    "assert sia_service is not None\n",
    "\n",
    "afwDisplay.setDefaultBackend('matplotlib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6faf6e-9bd9-4bc4-9a7a-b344a61bd95f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T23:59:54.263640Z",
     "iopub.status.busy": "2026-02-16T23:59:54.263291Z",
     "iopub.status.idle": "2026-02-16T23:59:54.268784Z",
     "shell.execute_reply": "2026-02-16T23:59:54.268078Z",
     "shell.execute_reply.started": "2026-02-16T23:59:54.263613Z"
    }
   },
   "source": [
    "Load in DP1 data (from one of three sites, or from all three sites). Option to retrieve data from .fits files to avoid querying TAP service (takes a long time). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540149f2-f109-4861-a2f3-cabe96d9434f",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "#                            CONFIGURATION                                      #\n",
    "################################################################################\n",
    "\n",
    "FETCH_FROM_SERVER = False    # True: Query TAP service | False: Load from .fits files\n",
    "LOAD_ALL_SITES = True       # True: Merge all sites | False: Single site only\n",
    "SITE = 'ecdfs'              # Options: 'ecdfs', 'galactic', 'ecliptic'\n",
    "ALL_SITES = ['ecdfs', 'galactic', 'ecliptic']\n",
    "\n",
    "################################################################################\n",
    "\n",
    "\n",
    "def set_coords(site):\n",
    "    match site:\n",
    "        case 'ecdfs':\n",
    "            return 53.16, -28.10\n",
    "        case 'galactic':\n",
    "            return 95.0, -25.0\n",
    "        case 'ecliptic':\n",
    "            return 37.98, 7.015\n",
    "\n",
    "def get_title():\n",
    "    if LOAD_ALL_SITES:\n",
    "        return 'All 3 Sites'\n",
    "    else:\n",
    "        match SITE:\n",
    "            case 'ecdfs':\n",
    "                return 'ECDFS'\n",
    "            case 'galactic':\n",
    "                return 'Low Galactic Latitude Field'\n",
    "            case 'ecliptic':\n",
    "                return 'Low Ecliptic Latitude Field'\n",
    "\n",
    "def fetch_site_data(site, service):\n",
    "    \"\"\"Fetch data from server for a given site.\"\"\"\n",
    "    ra_cen, dec_cen = set_coords(site)\n",
    "    \n",
    "    query = \"\"\"SELECT apFlux, apFlux_flag, apFlux_flag_apertureTruncated, apFluxErr, \n",
    "        band, bboxSize, centroid_flag, coord_dec, coord_ra, \n",
    "        dec, decErr, detector, diaObjectId, diaSourceId, \n",
    "        dipoleAngle, dipoleChi2, dipoleFitAttempted, dipoleFluxDiff, dipoleFluxDiffErr, \n",
    "        dipoleLength, dipoleMeanFlux, dipoleMeanFluxErr, dipoleNdata, \n",
    "        extendedness, forced_PsfFlux_flag, forced_PsfFlux_flag_edge, \n",
    "        forced_PsfFlux_flag_noGoodPixels, isDipole, \n",
    "        ixx, ixxPSF, ixy, ixyPSF, iyy, iyyPSF, \n",
    "        midpointMjdTai, parentDiaSourceId, \n",
    "        pixelFlags, pixelFlags_bad, pixelFlags_cr, pixelFlags_crCenter, \n",
    "        pixelFlags_edge, pixelFlags_injected, pixelFlags_injected_template, \n",
    "        pixelFlags_injected_templateCenter, pixelFlags_injectedCenter, \n",
    "        pixelFlags_interpolated, pixelFlags_interpolatedCenter, \n",
    "        pixelFlags_nodata, pixelFlags_nodataCenter, pixelFlags_offimage, \n",
    "        pixelFlags_saturated, pixelFlags_saturatedCenter, \n",
    "        pixelFlags_streak, pixelFlags_streakCenter, \n",
    "        pixelFlags_suspect, pixelFlags_suspectCenter, \n",
    "        psfChi2, psfFlux, psfFlux_flag, psfFlux_flag_edge, \n",
    "        psfFlux_flag_noGoodPixels, psfFluxErr, psfNdata, \n",
    "        ra, ra_dec_Cov, raErr, reliability, \n",
    "        scienceFlux, scienceFluxErr, \n",
    "        shape_flag, shape_flag_no_pixels, shape_flag_not_contained, \n",
    "        shape_flag_parent_source, snr, ssObjectId, \n",
    "        trail_flag_edge, trailAngle, trailDec, trailFlux, trailLength, trailRa, \n",
    "        visit, x, xErr, y, yErr\n",
    "        FROM dp1.DiaSource\n",
    "        WHERE CONTAINS(POINT('ICRS', ra, dec),\n",
    "        CIRCLE('ICRS', {}, {}, 1.0)) = 1\n",
    "        ORDER BY diaSourceId ASC\"\"\".format(ra_cen, dec_cen)\n",
    "    \n",
    "    print(f\"Querying {site}...\")\n",
    "    print(query)\n",
    "    \n",
    "    job = service.submit_job(query)\n",
    "    job.run()\n",
    "    job.wait(phases=['COMPLETED', 'ERROR'])\n",
    "    print(f'Job phase is {job.phase}')\n",
    "    \n",
    "    if job.phase == 'ERROR':\n",
    "        job.raise_if_error()\n",
    "    assert job.phase == 'COMPLETED'\n",
    "    \n",
    "    results = job.fetch_result().to_table()\n",
    "    print(f\"Retrieved {len(results)} rows with {len(results.colnames)} columns\")\n",
    "    \n",
    "    results.write(f'{site}.fits', format='fits', overwrite=True)\n",
    "    print(f\"Saved {len(results)} rows to {site}.fits\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "if FETCH_FROM_SERVER:\n",
    "    if LOAD_ALL_SITES:\n",
    "        all_results = []\n",
    "        for s in ALL_SITES:\n",
    "            result = fetch_site_data(s, service)\n",
    "            result['site'] = s\n",
    "            all_results.append(result)\n",
    "        results = vstack(all_results)\n",
    "        print(f\"Merged {len(results)} total rows from all sites\")\n",
    "    else:\n",
    "        results = fetch_site_data(SITE, service)\n",
    "else:\n",
    "    if LOAD_ALL_SITES:\n",
    "        all_results = []\n",
    "        for s in ALL_SITES:\n",
    "            data = Table.read(f'{s}.fits')\n",
    "            print(f\"Loaded {len(data)} rows from {s}.fits\")\n",
    "            data['site'] = s\n",
    "            all_results.append(data)\n",
    "        results = vstack(all_results)\n",
    "        print(f\"Merged {len(results)} total rows from all sites\")\n",
    "    else:\n",
    "        results = Table.read(f'{SITE}.fits')\n",
    "        print(f\"Loaded {len(results)} rows from {SITE}.fits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca1294b-cda4-4f65-b5eb-bf69ebc116c3",
   "metadata": {},
   "source": [
    "Generated columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96774d30-5345-442c-bf67-22e4ed1db6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_engineered_features(table):\n",
    "    names = table.colnames\n",
    "    names.remove('diaSourceId')\n",
    "    names.insert(0, 'diaSourceId')\n",
    "    table = table[names]\n",
    "    \n",
    "    # Engineered features\n",
    "    table['flux_ext'] = table['apFlux'] / table['psfFlux']\n",
    "    \n",
    "    table['ellip_ext'] = (\n",
    "        (np.sqrt((table['ixx'] - table['iyy'])**2 + 4 * table['ixy']**2) / \n",
    "         (table['ixx'] + table['iyy'])) - \n",
    "        (np.sqrt((table['ixxPSF'] - table['iyyPSF'])**2 + 4 * table['ixyPSF']**2) / \n",
    "         (table['ixxPSF'] + table['iyyPSF']))\n",
    "    )\n",
    "    \n",
    "    table['i_ext'] = (table['ixx'] + table['iyy']) / (table['ixxPSF'] + table['iyyPSF'])\n",
    "    \n",
    "    table['template_flux'] = table['scienceFlux'] - table['psfFlux']\n",
    "    table['temp_sci_flux_ratio'] = table['template_flux'] / table['scienceFlux']\n",
    "    \n",
    "    # For FWHM circle on plot (converted to pixels)\n",
    "    table['psf_fwhm'] = (table['ixxPSF'] * table['iyyPSF'] - table['ixyPSF']**2)**(1/4) * 2.35482 * 5\n",
    "    \n",
    "    return table\n",
    "\n",
    "results = add_engineered_features(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda3d472-dead-441f-b8de-80a1dfd8c9f3",
   "metadata": {},
   "source": [
    "DP1 data summary plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce8c5ff-79b1-4a5d-a030-2690a677ffbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "SHOW_INSET = False\n",
    "\n",
    "band_colors = {\n",
    "    'u': '#0c71ff',\n",
    "    'g': '#49be61',\n",
    "    'r': '#c61c00',\n",
    "    'i': '#ffc200',\n",
    "    'z': '#f341a2',\n",
    "    'y': '#5d0000'\n",
    "}\n",
    "\n",
    "BAND_ORDER = ['u', 'g', 'r', 'i', 'z', 'y']\n",
    "\n",
    "unique_visits_per_band = {}\n",
    "for band_name in np.unique(results['band']):\n",
    "    band_mask = results['band'] == band_name\n",
    "    unique_visits_per_band[band_name] = len(np.unique(results['visit'][band_mask]))\n",
    "\n",
    "sources_per_band = {}\n",
    "for band_name in np.unique(results['band']):\n",
    "    band_mask = results['band'] == band_name\n",
    "    sources_per_band[band_name] = np.sum(band_mask)\n",
    "\n",
    "sources_per_visit_by_band = {}\n",
    "for band_name in np.unique(results['band']):\n",
    "    band_mask = results['band'] == band_name\n",
    "    band_data = results[band_mask]\n",
    "    \n",
    "    unique_visits = np.unique(band_data['visit'])\n",
    "    sources_per_visit = []\n",
    "    \n",
    "    for visit in unique_visits:\n",
    "        visit_mask = band_data['visit'] == visit\n",
    "        sources_per_visit.append(np.sum(visit_mask))\n",
    "    \n",
    "    sources_per_visit_by_band[band_name] = np.array(sources_per_visit)\n",
    "\n",
    "total_visits = sum(unique_visits_per_band.values())\n",
    "total_sources = sum(sources_per_band.values())\n",
    "\n",
    "fig = plt.figure(figsize=(14, 10))\n",
    "gs = fig.add_gridspec(2, 2, hspace=0.3, wspace=0.3)\n",
    "\n",
    "fig.suptitle(f'DP1 Information, {get_title()}', fontsize=16, fontweight='bold')\n",
    "\n",
    "bands = [b for b in BAND_ORDER if b in unique_visits_per_band]\n",
    "colors = [band_colors[b] for b in bands]\n",
    "\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "visits = [unique_visits_per_band[b] for b in bands]\n",
    "bars1 = ax1.bar(bands, visits, color=colors, alpha=0.7, edgecolor='black')\n",
    "ax1.set_xlabel('Band', fontsize=12)\n",
    "ax1.set_ylabel('Number of Visits', fontsize=12)\n",
    "ax1.set_title('Number of Visits per Band', fontsize=13, fontweight='bold')\n",
    "ax1.set_ylim(0, 250)\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "for bar in bars1:\n",
    "    height = bar.get_height()\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{int(height)}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "ax1.text(0.98, 0.98, f'Total: {total_visits}', transform=ax1.transAxes,\n",
    "        fontsize=11, verticalalignment='top', horizontalalignment='right',\n",
    "        bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.7))\n",
    "\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "sources = [sources_per_band[b] for b in bands]\n",
    "bars2 = ax2.bar(bands, sources, color=colors, alpha=0.7, edgecolor='black')\n",
    "ax2.set_xlabel('Band', fontsize=12)\n",
    "ax2.set_ylabel('Number of DIA Sources', fontsize=12)\n",
    "ax2.set_title('DIA Sources per Band', fontsize=13, fontweight='bold')\n",
    "ax2.set_ylim(0, 300000)\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "for bar in bars2:\n",
    "    height = bar.get_height()\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{int(height)}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "ax2.text(0.98, 0.98, f'Total: {total_sources}', transform=ax2.transAxes,\n",
    "        fontsize=11, verticalalignment='top', horizontalalignment='right',\n",
    "        bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.7))\n",
    "\n",
    "ax3 = fig.add_subplot(gs[1, :])\n",
    "all_data = [sources_per_visit_by_band[b] for b in bands]\n",
    "\n",
    "stats_text = []\n",
    "for band in bands:\n",
    "    data = sources_per_visit_by_band[band]\n",
    "    mean_val = np.mean(data)\n",
    "    std_val = np.std(data)\n",
    "    stats_text.append(f'{band}: μ={mean_val:.1f}, σ={std_val:.1f}')\n",
    "\n",
    "bin_width = 100\n",
    "all_combined = np.concatenate(all_data)\n",
    "bins = np.arange(0, np.max(all_combined) + bin_width, bin_width)\n",
    "\n",
    "n, bins, patches = ax3.hist(all_data, bins=bins, label=bands, \n",
    "                             color=colors, alpha=0.7, \n",
    "                             edgecolor='black', stacked=True)\n",
    "\n",
    "ax3.set_xlabel('DIA Sources per Visit', fontsize=12)\n",
    "ax3.set_ylabel('Frequency', fontsize=12)\n",
    "ax3.set_title('Distribution of DIA Sources per Visit', \n",
    "              fontsize=13, fontweight='bold')\n",
    "ax3.set_xlim(0, 5000)\n",
    "ax3.set_ylim(0, 250)\n",
    "ax3.legend(loc='upper right', fontsize=10)\n",
    "ax3.grid(axis='y', alpha=0.3)\n",
    "\n",
    "stats_str = '\\n'.join(stats_text)\n",
    "ax3.text(0.98, 0.4, stats_str, transform=ax3.transAxes,\n",
    "        fontsize=10, verticalalignment='center', horizontalalignment='right',\n",
    "        bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "if SHOW_INSET:\n",
    "    axins = inset_axes(ax3, width=\"35%\", height=\"45%\", loc='upper center',\n",
    "                       bbox_to_anchor=(0, 0, 1, 1),\n",
    "                       bbox_transform=ax3.transAxes)\n",
    "    \n",
    "    axins.hist(all_data, bins=bins, label=bands, \n",
    "               color=colors, alpha=0.7, \n",
    "               edgecolor='black', stacked=True)\n",
    "    \n",
    "    axins.set_xlim(500, 5000)\n",
    "    axins.set_ylim(0, 50)\n",
    "    \n",
    "    axins.set_xlabel('Sources/Visit', fontsize=9)\n",
    "    axins.set_ylabel('Frequency', fontsize=9)\n",
    "    axins.tick_params(labelsize=8)\n",
    "    axins.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    rect = Rectangle((500, 0), 4500, 50, linewidth=1.5, \n",
    "                    edgecolor='red', facecolor='none', linestyle='--')\n",
    "    ax3.add_patch(rect)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8568f71-6183-41ef-a600-bbb6ebe70a64",
   "metadata": {},
   "source": [
    "## 2. Data filtering & additional calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0464acd9-cdb3-405c-bb40-1c9c548eea6f",
   "metadata": {},
   "source": [
    "Dictionary of all thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5b2c60-9e23-48ce-bba1-1bf72850dac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = {\n",
    "    'snr': 5,\n",
    "    'flux_ext': 0.35,\n",
    "    'i_ext': 0.5,\n",
    "    'ellip_ext': 0.2,\n",
    "    'temp_sci_flux_ratio': 0.85,\n",
    "    'flux_caps': {\n",
    "        'u': 88644.7,\n",
    "        'g': 118074.2,\n",
    "        'r': 166872.5,\n",
    "        'i': 203090.9,\n",
    "        'z': 257254.0,\n",
    "        'y': 264794.0,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c9e203-5981-4823-9b69-b2460a8b12d0",
   "metadata": {},
   "source": [
    "Quality filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9565d00-8c61-4714-946e-517c11937aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = results.copy()\n",
    "sel_snr = filtered['snr'] > thresholds['snr']\n",
    "filtered = filtered[sel_snr]\n",
    "sel_no_flag = ~filtered['apFlux_flag']\n",
    "sel_no_flag &= ~filtered['psfFlux_flag']\n",
    "sel_no_flag &= ~filtered['pixelFlags_cr']\n",
    "sel_no_flag &= ~filtered['pixelFlags_bad']\n",
    "sel_no_flag &= ~filtered['pixelFlags_nodata']\n",
    "sel_no_flag &= ~filtered['pixelFlags_interpolated']\n",
    "sel_no_flag &= ~filtered['pixelFlags_saturated']\n",
    "sel_no_flag &= ~filtered['pixelFlags_suspect']\n",
    "filtered = filtered[sel_no_flag]\n",
    "same_sign = ((filtered['psfFlux'] > 0) & (filtered['apFlux'] > 0) & (filtered['scienceFlux'] > 0)) | \\\n",
    "            ((filtered['psfFlux'] < 0) & (filtered['apFlux'] < 0) & (filtered['scienceFlux'] < 0))\n",
    "filtered = filtered[same_sign]\n",
    "\n",
    "print(len(filtered))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab1ab2b-acf4-4797-b6a7-70c8b93daef9",
   "metadata": {},
   "source": [
    "Ellipticity, moving object, and flux threshold filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52731970-3767-4e33-bcb4-ede198f41d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_s = filtered\n",
    "\n",
    "## extendedness filter\n",
    "ext_filter = (results_s['flux_ext'] > thresholds['flux_ext']) & \\\n",
    "             (results_s['i_ext'] > thresholds['i_ext']) & \\\n",
    "             (results_s['ellip_ext'] > thresholds['ellip_ext'])\n",
    "results_s = results_s[ext_filter]\n",
    "\n",
    "## moving object filter\n",
    "moving_obj_filter = results_s['temp_sci_flux_ratio'] > thresholds['temp_sci_flux_ratio']\n",
    "results_s = results_s[moving_obj_filter]\n",
    "\n",
    "## flux threshold filter\n",
    "threshold_array = np.array([thresholds['flux_caps'][band] for band in results_s['band']])\n",
    "flux_cap = results_s['template_flux'] < threshold_array\n",
    "results_s = results_s[flux_cap]\n",
    "\n",
    "print(len(results_s))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89a7163-f832-433a-b2e9-256215e1cbdd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-17T00:11:01.407396Z",
     "iopub.status.busy": "2026-02-17T00:11:01.407043Z",
     "iopub.status.idle": "2026-02-17T00:11:01.411684Z",
     "shell.execute_reply": "2026-02-17T00:11:01.410930Z",
     "shell.execute_reply.started": "2026-02-17T00:11:01.407373Z"
    }
   },
   "source": [
    "Plot: ellipticity difference metric vs. two calculated extendedness metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba5a2e3-8a6e-475e-9b44-2607c0514e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "y_data = filtered['i_ext']\n",
    "x_data = np.log10(filtered['flux_ext'])\n",
    "\n",
    "snr_data = filtered['ellip_ext']\n",
    "\n",
    "scatter = ax.scatter(x_data, y_data, \n",
    "                     alpha=0.5, s=1, c=snr_data, \n",
    "                     cmap='viridis_r', label=None, vmin=0, vmax=1)\n",
    "\n",
    "ax.set_xlabel('log10(apFlux/psfFlux)', fontsize=12)\n",
    "ax.set_ylabel('(ixx+iyy) / (ixxPSF+iyyPSF)', fontsize=12)\n",
    "ax.set_title(f'Ellipticity Difference, {get_title()}', fontsize=14)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_xlim(-1, 1)\n",
    "ax.set_ylim(-1, 5)\n",
    "\n",
    "cbar = plt.colorbar(scatter, ax=ax, label='ellipticity')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cba4a3e-3a76-4101-b286-6b640d90c1a1",
   "metadata": {},
   "source": [
    "Plot: sources that pass extendedness filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45158135-9974-4004-a425-a3ac86bebb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 5))\n",
    "\n",
    "y_data1 = filtered['i_ext']\n",
    "x_data1 = np.log10(filtered['flux_ext'])\n",
    "\n",
    "y_data2 = results_s['i_ext']\n",
    "x_data2 = np.log10(results_s['flux_ext'])\n",
    "\n",
    "ax.scatter(x_data1, y_data1, \n",
    "           alpha=0.5, s=1, c='blue', label='All sources after filter')\n",
    "\n",
    "ax.scatter(x_data2, y_data2, \n",
    "           alpha=1, s=2, c='red', label='Extended sources')\n",
    "\n",
    "ax.set_xlabel('log10(apFlux/psfFlux)', fontsize=12)\n",
    "ax.set_ylabel('(ixx+iyy) / (ixxPSF+iyyPSF)', fontsize=12)\n",
    "ax.set_title(f'Extendedness filter, {get_title()}', fontsize=14)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend(markerscale=5)\n",
    "ax.set_xlim(-1, 1)\n",
    "ax.set_ylim(-1, 5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c58375a-32be-4be3-911d-c9553218435f",
   "metadata": {},
   "source": [
    "Corner plot: extendedness metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd72e31-642b-4b0b-8ff6-024999200195",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_corner = ['flux_ext', 'ellip_ext', 'i_ext', 'extendedness']\n",
    "axes_scale = ['log', 'linear', 'linear', 'linear']\n",
    "ranges = [(0.1, 10.0), (0, 1), (0, 4), (0, 1)]\n",
    "data_array = [filtered[col] for col in columns_corner]\n",
    "labels = [\n",
    "    'Flux Ext.',\n",
    "    'Ellip. Diff.',\n",
    "    'Moment Ext.',\n",
    "    'Extendedness'\n",
    "]\n",
    "\n",
    "fig = corner.corner(np.array(data_array).T, \n",
    "                    labels=labels,\n",
    "                    axes_scale=axes_scale,\n",
    "                    range=ranges,\n",
    "                    fill_contours=True, \n",
    "                    smooth=0.7, \n",
    "                    show_titles=False, \n",
    "                    color='grey',\n",
    "                    plot_datapoints=True,\n",
    "                    plot_contours=True,\n",
    "                    plot_density=True,\n",
    "                    bins=15)\n",
    "\n",
    "axes = np.array(fig.axes).reshape((len(columns_corner), len(columns_corner)))\n",
    "for i in range(len(columns_corner)):\n",
    "    for j in range(i):\n",
    "        ax = axes[i, j]\n",
    "        ax.scatter(data_array[j], data_array[i], s=2, alpha=0.03, color='black', rasterized=True)\n",
    "\n",
    "fig.suptitle(f'Extendedness Parameter Correlations, {get_title()}', fontsize=18, fontweight='bold', y=0.99)\n",
    "\n",
    "# Text box moved up and left with padding\n",
    "equation_text = (\n",
    "    r'$\\mathrm{Flux\\ Ext.} = \\log(\\mathrm{Aperture\\ flux} / \\mathrm{PSF\\ flux})$' + '\\n\\n' +\n",
    "    r'$\\mathrm{Moment\\ Ext.} = \\frac{I_{xx} + I_{yy}}{I_{xx}^{\\mathrm{PSF}} + I_{yy}^{\\mathrm{PSF}}}$' + '\\n\\n' +\n",
    "    r'$\\mathrm{Ellip.\\ Diff.} = \\frac{\\sqrt{(I_{xx}-I_{yy})^2+4I_{xy}^2}}{I_{xx}+I_{yy}} - '\n",
    "    r'\\frac{\\sqrt{(I_{xx}^{\\mathrm{PSF}}-I_{yy}^{\\mathrm{PSF}})^2+4I_{xy}^{\\mathrm{PSF}\\ 2}}}'\n",
    "    r'{I_{xx}^{\\mathrm{PSF}}+I_{yy}^{\\mathrm{PSF}}}$'\n",
    ")\n",
    "\n",
    "fig.text(0.55, 0.82, equation_text, fontsize=13,\n",
    "         bbox=dict(boxstyle='round,pad=0.8', facecolor='white', edgecolor='black', alpha=0.9),\n",
    "         verticalalignment='top')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3817ed-69fb-4386-aa2b-a355dbef6075",
   "metadata": {},
   "source": [
    "View sources that pass all filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e73b029-6c30-4d9f-bb46-d81a8186d6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13e7d0d-67fa-4c6b-bcf0-5d294449d282",
   "metadata": {},
   "source": [
    "## 3. Gallery view of sources passing all filters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e8fb02-1073-443d-8f17-f9a3dd615835",
   "metadata": {},
   "source": [
    "This produces a gallery of DIA Sources in results_s table. Choose the number of rows and columns for the gallery. It also pulls Legacy Survey cutouts for each. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbce1625-ae33-4059-9bfc-9a98f204c5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# CONFIGURATION\n",
    "# ==============================================================================\n",
    "LAYOUT_COLS = 2  # Number of columns\n",
    "LAYOUT_ROWS = 5  # Number of rows\n",
    "# ==============================================================================\n",
    "\n",
    "from matplotlib.patches import Circle\n",
    "from astropy.visualization import ZScaleInterval\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "def get_cutout_with_retry(dl_result, spherePoint, session, fov, max_retries=3):\n",
    "    \"\"\"Get a cutout with exponential backoff retry logic.\"\"\"\n",
    "    sq = SodaQuery.from_resource(dl_result,\n",
    "                                 dl_result.get_adhocservice_by_id(\"cutout-sync-exposure\"),\n",
    "                                 session=session)\n",
    "    sphereRadius = fov * u.deg\n",
    "    sq.circle = (spherePoint.getRa().asDegrees() * u.deg,\n",
    "                 spherePoint.getDec().asDegrees() * u.deg,\n",
    "                 sphereRadius)\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            cutout_bytes = sq.execute_stream().read()\n",
    "            sq.raise_if_error()\n",
    "            mem = MemFileManager(len(cutout_bytes))\n",
    "            mem.setData(cutout_bytes, len(cutout_bytes))\n",
    "            return ExposureF(mem)\n",
    "        except Exception as e:\n",
    "            if '429' in str(e) and attempt < max_retries - 1:\n",
    "                wait_time = (2 ** attempt) + random.uniform(0, 1)\n",
    "                time.sleep(wait_time)\n",
    "            else:\n",
    "                raise\n",
    "\n",
    "def fetch_images_for_row(row, sia_service, get_pyvo_auth, fov=0.003):\n",
    "    \"\"\"Fetch all images for a single row with rate limiting.\"\"\"\n",
    "    try:\n",
    "        row_start = time.time()\n",
    "        \n",
    "        ra = row['ra']\n",
    "        dec = row['dec']\n",
    "        visit = row['visit']\n",
    "        band = row['band']\n",
    "        diaSourceId = row['diaSourceId']\n",
    "        snr = row['snr']\n",
    "        extendedness = row['extendedness']\n",
    "        flux_ext = row['flux_ext']\n",
    "        ellip_ext = row['ellip_ext']\n",
    "        i_ext = row['i_ext']\n",
    "        template_flux = row['template_flux']\n",
    "        scienceFlux = row['scienceFlux']\n",
    "        psfFlux = row['psfFlux']\n",
    "        apFlux = row['apFlux']\n",
    "        psf_fwhm = row['psf_fwhm']\n",
    "        \n",
    "        spherePoint = geom.SpherePoint(ra*geom.degrees, dec*geom.degrees)\n",
    "        circle = (ra, dec, 0.0001)\n",
    "        \n",
    "        t0 = time.time()\n",
    "        lvl2_table = sia_service.search(pos=circle, calib_level=2).to_table()\n",
    "        sel = lvl2_table['dataproduct_subtype'] == 'lsst.visit_image'\n",
    "        sel &= lvl2_table['lsst_visit'] == visit\n",
    "        sci_table = lvl2_table[sel]\n",
    "        \n",
    "        if len(sci_table) == 0:\n",
    "            return None, f\"No science images found\"\n",
    "        \n",
    "        lvl3_table = sia_service.search(pos=circle, calib_level=3).to_table()\n",
    "        search_time = time.time() - t0\n",
    "        \n",
    "        sel = lvl3_table['dataproduct_subtype'] == 'lsst.template_coadd'\n",
    "        sel &= lvl3_table['lsst_band'] == band\n",
    "        ref_table = lvl3_table[sel]\n",
    "        \n",
    "        if len(ref_table) == 0:\n",
    "            return None, f\"No template images found\"\n",
    "        \n",
    "        sel = lvl3_table['dataproduct_subtype'] == 'lsst.difference_image'\n",
    "        sel &= lvl3_table['lsst_visit'] == visit\n",
    "        diff_table = lvl3_table[sel]\n",
    "        \n",
    "        if len(diff_table) == 0:\n",
    "            return None, f\"No difference images found\"\n",
    "        \n",
    "        t0 = time.time()\n",
    "        dl_result_sci = DatalinkResults.from_result_url(sci_table['access_url'][0], session=get_pyvo_auth())\n",
    "        dl_result_ref = DatalinkResults.from_result_url(ref_table['access_url'][0], session=get_pyvo_auth())\n",
    "        dl_result_diff = DatalinkResults.from_result_url(diff_table['access_url'][0], session=get_pyvo_auth())\n",
    "        datalink_time = time.time() - t0\n",
    "        \n",
    "        t0 = time.time()\n",
    "        sci = get_cutout_with_retry(dl_result_sci, spherePoint, get_pyvo_auth(), fov)\n",
    "        time.sleep(0.3)\n",
    "        ref = get_cutout_with_retry(dl_result_ref, spherePoint, get_pyvo_auth(), fov)\n",
    "        time.sleep(0.3)\n",
    "        diff = get_cutout_with_retry(dl_result_diff, spherePoint, get_pyvo_auth(), fov)\n",
    "        download_time = time.time() - t0\n",
    "        \n",
    "        t0 = time.time()\n",
    "        warper_config = WarperConfig()\n",
    "        warper = Warper.fromConfig(warper_config)\n",
    "        sci_wcs = sci.getWcs()\n",
    "        sci_bbox = sci.getBBox()\n",
    "        warped_ref = warper.warpExposure(sci_wcs, ref, destBBox=sci_bbox)\n",
    "        warp_time = time.time() - t0\n",
    "        \n",
    "        total_time = time.time() - row_start\n",
    "        \n",
    "        return {\n",
    "            'visit': visit,\n",
    "            'band': band,\n",
    "            'diaSourceId': diaSourceId,\n",
    "            'ra': ra,\n",
    "            'dec': dec,\n",
    "            'sci': sci,\n",
    "            'snr': snr,\n",
    "            'extendedness': extendedness,\n",
    "            'flux_ext': flux_ext,\n",
    "            'ellip_ext': ellip_ext,\n",
    "            'i_ext': i_ext,\n",
    "            'template_flux': template_flux,\n",
    "            'scienceFlux': scienceFlux,\n",
    "            'psfFlux': psfFlux,\n",
    "            'apFlux': apFlux,\n",
    "            'psf_fwhm': psf_fwhm,\n",
    "            'warped_ref': warped_ref,\n",
    "            'diff': diff,\n",
    "            'search_time': search_time,\n",
    "            'datalink_time': datalink_time,\n",
    "            'download_time': download_time,\n",
    "            'warp_time': warp_time,\n",
    "            'total_time': total_time\n",
    "        }, None\n",
    "        \n",
    "    except Exception as e:\n",
    "        return None, str(e)\n",
    "\n",
    "n_images = LAYOUT_COLS * LAYOUT_ROWS\n",
    "sample_indices = np.random.choice(len(results_s), size=min(n_images, len(results_s)), replace=False)\n",
    "sampled_rows = [results_s[i] for i in sample_indices]\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Starting gallery creation at {datetime.now().strftime('%H:%M:%S')}\")\n",
    "print(f\"Layout: {LAYOUT_COLS} columns x {LAYOUT_ROWS} rows = {n_images} images\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "start_time = time.time()\n",
    "\n",
    "gallery_results = []\n",
    "with ThreadPoolExecutor(max_workers=2) as executor:\n",
    "    futures = {executor.submit(fetch_images_for_row, row, sia_service, get_pyvo_auth): idx \n",
    "               for idx, row in enumerate(sampled_rows)}\n",
    "    \n",
    "    for future in as_completed(futures):\n",
    "        idx = futures[future]\n",
    "        result, error = future.result()\n",
    "        \n",
    "        if result:\n",
    "            print(f\"[{datetime.now().strftime('%H:%M:%S')}] ✓ {len(gallery_results)+1}/{n_images}: visit={result['visit']}, diaSourceId={result['diaSourceId']}, time={result['total_time']:.1f}s\")\n",
    "            gallery_results.append(result)\n",
    "        else:\n",
    "            print(f\"[{datetime.now().strftime('%H:%M:%S')}] ✗ Failed: {error}\")\n",
    "        \n",
    "        if len(gallery_results) >= n_images:\n",
    "            break\n",
    "\n",
    "fetch_time = time.time() - start_time\n",
    "print(f\"\\nAll images fetched in {fetch_time:.1f}s ({fetch_time/60:.1f} min)\")\n",
    "print(f\"Average per image set: {fetch_time/len(gallery_results):.1f}s\\n\")\n",
    "\n",
    "actual_n_images = len(gallery_results)\n",
    "if actual_n_images < n_images:\n",
    "    print(f\"\\n⚠️  Warning: Only {actual_n_images} images available, but layout is {LAYOUT_COLS}x{LAYOUT_ROWS}={n_images}\")\n",
    "    print(f\"Remaining {n_images - actual_n_images} cells will be left empty/white\\n\")\n",
    "\n",
    "print(\"Creating plots...\")\n",
    "plot_start = time.time()\n",
    "\n",
    "fig = plt.figure(figsize=(LAYOUT_COLS * 9, LAYOUT_ROWS * 3))\n",
    "gs = GridSpec(LAYOUT_ROWS, LAYOUT_COLS, figure=fig, \n",
    "              hspace=0.02, wspace=0.02,\n",
    "              left=0.01, right=0.99, top=0.99, bottom=0.01)\n",
    "\n",
    "for idx in range(n_images):\n",
    "    gallery_row = idx // LAYOUT_COLS\n",
    "    gallery_col = idx % LAYOUT_COLS\n",
    "    \n",
    "    gs_sub = gs[gallery_row, gallery_col].subgridspec(1, 3, wspace=0.01)\n",
    "    \n",
    "    ax1 = fig.add_subplot(gs_sub[0, 0])\n",
    "    ax2 = fig.add_subplot(gs_sub[0, 1])\n",
    "    ax3 = fig.add_subplot(gs_sub[0, 2])\n",
    "    \n",
    "    if idx < len(gallery_results):\n",
    "        result = gallery_results[idx]\n",
    "        \n",
    "        for ax, img in [(ax1, result['sci']), (ax2, result['warped_ref']), (ax3, result['diff'])]:\n",
    "            interval = ZScaleInterval()\n",
    "            vmin, vmax = interval.get_limits(img.image.array)\n",
    "            \n",
    "            ax.imshow(img.image.array, cmap='gray', origin='lower', \n",
    "                      vmin=vmin, vmax=vmax, aspect='equal', interpolation='nearest')\n",
    "            ax.set_axis_off()\n",
    "            ax.set_position(ax.get_position())\n",
    "            ax.margins(0, 0)\n",
    "            ax.set_xlim(0, img.image.array.shape[1])\n",
    "            ax.set_ylim(0, img.image.array.shape[0])\n",
    "        \n",
    "        ax1.text(0.02, 0.98, f'Visit: {result[\"visit\"]}\\nSNR: {result[\"snr\"]:.3f}\\nSci Flux: {result[\"scienceFlux\"]:.1f}', \n",
    "                 transform=ax1.transAxes, ha='left', va='top',\n",
    "                 fontsize=10, color='white',\n",
    "                 bbox=dict(boxstyle='round,pad=0.3', facecolor='black', alpha=0.7))\n",
    "        \n",
    "        ax1.text(0.02, 0.02, f'{result[\"band\"]}', \n",
    "                 transform=ax1.transAxes, ha='left', va='bottom',\n",
    "                 fontsize=16, color='white',\n",
    "                 bbox=dict(boxstyle='round,pad=0.3', facecolor='black', alpha=0.7))\n",
    "\n",
    "        ax2.text(0.02, 0.98, f'RA: {result[\"ra\"]}\\nDEC: {result[\"dec\"]}', \n",
    "                 transform=ax2.transAxes, ha='left', va='top',\n",
    "                 fontsize=10, color='white',\n",
    "                 bbox=dict(boxstyle='round,pad=0.3', facecolor='black', alpha=0.7))\n",
    "\n",
    "        ax2.text(0.02, 0.02, f'Template Flux: {result[\"template_flux\"]:.1f} ({(result[\"template_flux\"]/result[\"scienceFlux\"]*100):.0f}% sci flux)', \n",
    "                 transform=ax2.transAxes, ha='left', va='bottom',\n",
    "                 fontsize=10, color='white',\n",
    "                 bbox=dict(boxstyle='round,pad=0.3', facecolor='black', alpha=0.7))\n",
    "        \n",
    "        ax3.text(0.98, 0.98, f'DIASourceID: {result[\"diaSourceId\"]}\\nPSF Flux: {result[\"psfFlux\"]:.1f} | Ap Flux: {result[\"apFlux\"]:.1f}', \n",
    "                 transform=ax3.transAxes, ha='right', va='top',\n",
    "                 fontsize=10, color='white',\n",
    "                 bbox=dict(boxstyle='round,pad=0.3', facecolor='black', alpha=0.7))\n",
    "\n",
    "        ax3.text(0.98, 0.02, f'Ext.: {result[\"extendedness\"]:.3f}\\nLog Flux Ext.: {np.log10(result[\"flux_ext\"]):.3f}\\nEllip. Diff.: {result[\"ellip_ext\"]:.3f}\\nMoment Ext.: {result[\"i_ext\"]:.3f}', \n",
    "                 transform=ax3.transAxes, ha='right', va='bottom',\n",
    "                 fontsize=10, color='white',\n",
    "                 bbox=dict(boxstyle='round,pad=0.3', facecolor='black', alpha=0.7))\n",
    "        \n",
    "        psf_fwhm_pixels = result['psf_fwhm']\n",
    "        circle_x = psf_fwhm_pixels * 1.5\n",
    "        circle_y = psf_fwhm_pixels * 1.5\n",
    "        \n",
    "        circle = Circle((circle_x, circle_y), psf_fwhm_pixels / 2, \n",
    "                       fill=False, edgecolor='cyan', linewidth=2, alpha=0.8)\n",
    "        ax3.add_patch(circle)\n",
    "        \n",
    "        cross_length = psf_fwhm_pixels / 2\n",
    "        ax3.plot([circle_x - cross_length, circle_x + cross_length], \n",
    "                [circle_y, circle_y], \n",
    "                color='cyan', linewidth=2, alpha=0.8)\n",
    "        ax3.plot([circle_x, circle_x], \n",
    "                [circle_y - cross_length, circle_y + cross_length], \n",
    "                color='cyan', linewidth=2, alpha=0.8)\n",
    "        \n",
    "    else:\n",
    "        for ax in [ax1, ax2, ax3]:\n",
    "            ax.set_axis_off()\n",
    "\n",
    "plot_time = time.time() - plot_start\n",
    "print(f\"Plotting complete in {plot_time:.1f}s\")\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Complete at {datetime.now().strftime('%H:%M:%S')}\")\n",
    "print(f\"Total time: {total_time:.1f}s ({total_time/60:.1f} minutes)\")\n",
    "print(f\"Created {len(gallery_results)} image sets\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# ==============================================================================\n",
    "# LEGACY SURVEY IMAGE ARRAY\n",
    "# ==============================================================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Creating Legacy Survey cutout gallery...\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "def fetch_legacy_survey_cutout(ra, dec, pixscale=0.15, timeout=10, max_retries=3):\n",
    "    \"\"\"Fetch a cutout from Legacy Survey with retry logic.\"\"\"\n",
    "    url = f\"https://www.legacysurvey.org/viewer/cutout.jpg?ra={ra}&dec={dec}&layer=ls-dr9&pixscale={pixscale}\"\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = requests.get(url, timeout=timeout)\n",
    "            response.raise_for_status()\n",
    "            img = Image.open(BytesIO(response.content))\n",
    "            return np.array(img), None\n",
    "        except Exception as e:\n",
    "            if attempt < max_retries - 1:\n",
    "                wait_time = 1.0 + attempt\n",
    "                print(f\"    ⚠ Retry {attempt + 1}/{max_retries - 1} after {wait_time:.1f}s...\")\n",
    "                time.sleep(wait_time)\n",
    "            else:\n",
    "                return None, str(e)\n",
    "    \n",
    "    return None, \"Max retries exceeded\"\n",
    "\n",
    "print(\"Downloading Legacy Survey cutouts...\")\n",
    "legacy_start = time.time()\n",
    "legacy_images = []\n",
    "\n",
    "for idx, result in enumerate(gallery_results):\n",
    "    img, error = fetch_legacy_survey_cutout(result['ra'], result['dec'])\n",
    "    if img is not None:\n",
    "        legacy_images.append(img)\n",
    "        print(f\"✓ {idx+1}/{len(gallery_results)}: Downloaded cutout for DIASourceID {result['diaSourceId']}\")\n",
    "    else:\n",
    "        print(f\"✗ {idx+1}/{len(gallery_results)}: Failed to download - {error}\")\n",
    "        legacy_images.append(None)\n",
    "    time.sleep(0.1)\n",
    "\n",
    "legacy_fetch_time = time.time() - legacy_start\n",
    "print(f\"\\nLegacy Survey cutouts downloaded in {legacy_fetch_time:.1f}s\\n\")\n",
    "\n",
    "fig_legacy = plt.figure(figsize=(LAYOUT_COLS * 3, LAYOUT_ROWS * 3))\n",
    "gs_legacy = GridSpec(LAYOUT_ROWS, LAYOUT_COLS, figure=fig_legacy,\n",
    "                     hspace=0.02, wspace=0.02,\n",
    "                     left=0.01, right=0.99, top=0.99, bottom=0.01)\n",
    "\n",
    "for idx in range(n_images):\n",
    "    gallery_row = idx // LAYOUT_COLS\n",
    "    gallery_col = idx % LAYOUT_COLS\n",
    "    \n",
    "    ax = fig_legacy.add_subplot(gs_legacy[gallery_row, gallery_col])\n",
    "    \n",
    "    if idx < len(legacy_images) and legacy_images[idx] is not None:\n",
    "        ax.imshow(legacy_images[idx], origin='upper', aspect='equal', interpolation='nearest')\n",
    "        ax.set_axis_off()\n",
    "        ax.margins(0, 0)\n",
    "    else:\n",
    "        ax.set_axis_off()\n",
    "\n",
    "legacy_plot_time = time.time() - legacy_start - legacy_fetch_time\n",
    "print(f\"Legacy Survey plotting complete in {legacy_plot_time:.1f}s\")\n",
    "\n",
    "total_legacy_time = time.time() - legacy_start\n",
    "print(f\"Total Legacy Survey gallery time: {total_legacy_time:.1f}s\\n\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"Both galleries complete\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ee739f-b8f6-4e32-9ac9-5466e716f46a",
   "metadata": {},
   "source": [
    "## 4. Injected Source Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b5ac6b-bba3-4410-850f-a8445a5a35cd",
   "metadata": {},
   "source": [
    "Pull Shenming's injected sources & identify LAGN DIASources from injection coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff71ec31-1230-4756-b70b-91721cb55372",
   "metadata": {},
   "outputs": [],
   "source": [
    "inj_radec_files = sorted(glob('/home/sfu/shared_lagn_injection/v0.4/inj_radec*.fits'))\n",
    "print(\"Merging inj_radec files:\")\n",
    "for f in inj_radec_files:\n",
    "    print(f\"  {f}\")\n",
    "inj_radec = vstack([Table.read(f) for f in inj_radec_files])\n",
    "print(f\"Total inj_radec rows: {len(inj_radec)}\\n\")\n",
    "\n",
    "no_inj_sources_files = sorted(glob('/home/sfu/shared_lagn_injection/v0.4/diaSources_tab_*.csv'))\n",
    "print(\"Merging no_inj_sources files:\")\n",
    "for f in no_inj_sources_files:\n",
    "    print(f\"  {f}\")\n",
    "no_inj_sources = vstack([Table.read(f, format='csv') for f in no_inj_sources_files])\n",
    "print(f\"Total no_inj_sources rows: {len(no_inj_sources)}\\n\")\n",
    "\n",
    "inj_sources_files = sorted(glob('/home/sfu/shared_lagn_injection/v0.4/injected_diaSources_tab_*.csv'))\n",
    "print(\"Merging inj_sources files:\")\n",
    "for f in inj_sources_files:\n",
    "    print(f\"  {f}\")\n",
    "inj_sources = vstack([Table.read(f, format='csv') for f in inj_sources_files])\n",
    "print(f\"Total inj_sources rows: {len(inj_sources)}\\n\")\n",
    "\n",
    "def lagn_lookup(sources, lookup, max_sep=0.002):\n",
    "    src_coords = SkyCoord(ra=sources['ra'], dec=sources['dec'], unit='deg')\n",
    "    inj_coords = SkyCoord(ra=lookup['ra'], dec=lookup['dec'], unit='deg')\n",
    "    _, sep2d, _ = src_coords.match_to_catalog_sky(inj_coords)\n",
    "    return sep2d.deg < max_sep\n",
    "\n",
    "# Create the 'lagn' column\n",
    "inj_sources['lagn'] = lagn_lookup(inj_sources, inj_radec)\n",
    "inj_sources = add_engineered_features(inj_sources)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bb37fd-4baf-4f5e-b9a7-9224cca061f3",
   "metadata": {},
   "source": [
    "Plot of DIASources with & without injection. Includes injection coordinates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d210625e-e089-469e-a65b-07f9ee528ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8), dpi=300)\n",
    "plt.scatter(inj_sources['ra'], inj_sources['dec'], c='red', alpha=0.3, label='Sources, injection')\n",
    "plt.scatter(no_inj_sources['ra'], no_inj_sources['dec'], c='blue', alpha=0.3, label='Sources, no injection')\n",
    "plt.scatter(inj_radec['ra'], inj_radec['dec'], c='green', alpha=0.3, label='Injection coords.')\n",
    "\n",
    "plt.xlabel('RA (degrees)')\n",
    "plt.ylabel('Dec (degrees)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "ax = plt.gca()\n",
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af84b3a-0b37-4b4d-81f3-669a497eef32",
   "metadata": {},
   "source": [
    "Corner plot with DP1 DIASources (gray contours) and injected LAGN (green contours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4667ffb1-50d8-49cf-bea1-d37c08c08bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_corner = ['flux_ext', 'ellip_ext', 'i_ext', 'extendedness', 'psfChi2', 'trailLength', 'trailFlux', 'snr', 'temp_sci_flux_ratio',]\n",
    "axes_scale = ['log', 'linear', 'linear', 'linear', 'log', 'linear', 'log', 'log', 'linear']\n",
    "ranges = [(0.1, 10.0), (0, 1), (0, 4), (0, 1), (100, 10000), (0, 4), (1000, 100000), (1, 100), (0, 1)]\n",
    "\n",
    "data_array_all = [results[col] for col in columns_corner]\n",
    "data_array_lagn = [inj_sources[inj_sources['lagn']][col] for col in columns_corner]\n",
    "\n",
    "labels = [\n",
    "    'Flux Ext.',\n",
    "    'Ellip. Diff.',\n",
    "    'Moment Ext.',\n",
    "    'Extendedness',\n",
    "    'PSF χ²',\n",
    "    'Trail Length',\n",
    "    'Trail Flux',\n",
    "    'SNR',\n",
    "    'Temp./Sci. Flux'\n",
    "]\n",
    "\n",
    "fig = corner.corner(np.array(data_array_all).T, \n",
    "                    labels=labels,\n",
    "                    axes_scale=axes_scale,\n",
    "                    range=ranges,\n",
    "                    fill_contours=True, \n",
    "                    smooth=0.7, \n",
    "                    show_titles=False, \n",
    "                    color='grey',\n",
    "                    plot_datapoints=False,\n",
    "                    plot_contours=True,\n",
    "                    plot_density=True,\n",
    "                    bins=20,\n",
    "                    fig=plt.figure(figsize=(15, 15)),\n",
    "                    label_kwargs=dict(fontsize=12),\n",
    "                    max_n_ticks=3,\n",
    "                    hist_kwargs=dict(density=True)\n",
    "                    )\n",
    "\n",
    "fig = corner.corner(np.array(data_array_lagn).T,\n",
    "                    labels=labels,\n",
    "                    axes_scale=axes_scale,\n",
    "                    range=ranges,\n",
    "                    fill_contours=True,\n",
    "                    smooth=0.7,\n",
    "                    show_titles=False,\n",
    "                    color='green',\n",
    "                    plot_datapoints=False,\n",
    "                    plot_contours=True,\n",
    "                    plot_density=True,\n",
    "                    bins=20,\n",
    "                    fig=fig,\n",
    "                    label_kwargs=dict(fontsize=12),\n",
    "                    max_n_ticks=3,\n",
    "                    hist_kwargs=dict(density=True)\n",
    "                    )\n",
    "\n",
    "axes = np.array(fig.axes).reshape((len(columns_corner), len(columns_corner)))\n",
    "\n",
    "for ax in fig.axes:\n",
    "    ax.tick_params(labelsize=9)\n",
    "    for label in ax.get_xticklabels():\n",
    "        label.set_rotation(0)\n",
    "    ax.tick_params(axis='both', which='major', pad=2)\n",
    "\n",
    "col_indices = {col: columns_corner.index(col) for col in thresholds.keys() if col in columns_corner}\n",
    "\n",
    "for i in range(len(columns_corner)):\n",
    "    for j in range(i+1):\n",
    "        ax = axes[i, j]\n",
    "        \n",
    "        col_y = columns_corner[i]\n",
    "        col_x = columns_corner[j] if i != j else columns_corner[i]\n",
    "        \n",
    "        if i != j:\n",
    "            if col_x in col_indices:\n",
    "                threshold_x = thresholds[col_x]\n",
    "                ax.axvline(threshold_x, color='blue', linestyle='--', linewidth=1.5, alpha=0.6, zorder=5)\n",
    "                ax.axvspan(threshold_x, ranges[j][1], alpha=0.1, color='blue', zorder=1)\n",
    "            \n",
    "            if col_y in col_indices:\n",
    "                threshold_y = thresholds[col_y]\n",
    "                ax.axhline(threshold_y, color='blue', linestyle='--', linewidth=1.5, alpha=0.6, zorder=5)\n",
    "                ax.axhspan(threshold_y, ranges[i][1], alpha=0.1, color='blue', zorder=1)\n",
    "        \n",
    "        else:\n",
    "            if col_x in col_indices:\n",
    "                threshold = thresholds[col_x]\n",
    "                ax.axvline(threshold, color='blue', linestyle='--', linewidth=1.5, alpha=0.6, zorder=5)\n",
    "                ylim = ax.get_ylim()\n",
    "                ax.axvspan(threshold, ranges[i][1], alpha=0.1, color='blue', zorder=1)\n",
    "\n",
    "equation_text = (\n",
    "    r'$\\mathrm{Flux\\ Ext.} = \\log(\\mathrm{Aperture\\ flux} / \\mathrm{PSF\\ flux})$' + '\\n\\n' +\n",
    "    r'$\\mathrm{Moment\\ Ext.} = \\frac{I_{xx} + I_{yy}}{I_{xx}^{\\mathrm{PSF}} + I_{yy}^{\\mathrm{PSF}}}$' + '\\n\\n' +\n",
    "    r'$\\mathrm{Ellip.\\ Diff.} = \\frac{\\sqrt{(I_{xx}-I_{yy})^2+4I_{xy}^2}}{I_{xx}+I_{yy}} - '\n",
    "    r'\\frac{\\sqrt{(I_{xx}^{\\mathrm{PSF}}-I_{yy}^{\\mathrm{PSF}})^2+4I_{xy}^{\\mathrm{PSF}\\ 2}}}'\n",
    "    r'{I_{xx}^{\\mathrm{PSF}}+I_{yy}^{\\mathrm{PSF}}}$'\n",
    ")\n",
    "\n",
    "fig.text(0.55, 0.82, equation_text, fontsize=13,\n",
    "         bbox=dict(boxstyle='round,pad=0.8', facecolor='white', edgecolor='black', alpha=0.9),\n",
    "         verticalalignment='top')\n",
    "\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.lines import Line2D\n",
    "legend_elements = [\n",
    "    Patch(facecolor='grey', edgecolor='black', label='All DP1 DIASources'),\n",
    "    Patch(facecolor='green', edgecolor='darkgreen', label='Injected LAGN'),\n",
    "    Line2D([0], [0], color='blue', linestyle='--', linewidth=1.5, alpha=0.6, label='Selection Thresholds')\n",
    "]\n",
    "fig.legend(handles=legend_elements, loc='upper right', fontsize=15, framealpha=0.9)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
